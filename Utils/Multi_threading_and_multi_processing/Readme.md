## 多线程与多进程 
### 来源 
- https://zhuanlan.zhihu.com/p/46368084 
- https://www.zhihu.com/question/23474039/answer/269526476
- https://www.cnblogs.com/daisyforever/p/6013349.html

### 1. Introduction 
- **线程**就是操作系统调度的最小单元而**进程**是操作系统分配资源的最小单元;
- 一个应用程序至少包括一个进程，而一个进程可以包括多个线程；
- 每个进程在执行过程中拥有独立的内存单元，**而一个线程的多个进程在执行过程中共享内存**; 
- 任意时刻，一个CPU只能运行一个进程，其他进程处于非运行状态；
- 但是一个进程里可以有很多线程，每个线程都可以共享该进程的内存；
- 内存就那么大，会存在各个线程抢占的风险，为了防止这种情况，增加"互斥锁"（Mutual exclusion，缩写 Mutex），即一个线程在使用时，
其他线程必须等它结束，才可以继续使用；
- Python中的多线程，由于存在全局解释器锁GIL，不能发挥多线程的优势，
对所有面向I/O的（会调用内建的操作系统C代码的）程序来说，
GIL会在这个I/O调用之前被释放，以允许其他线程在这个线程等待I/O的时候运行。
如果某线程并未使用很多I/O操作，它会在自己的时间片内一直占用处理器和GIL。
也就是说，I/O密集型的Python程序比计算密集型的Python程序更能充分利用多线程的好处。
我们都知道，比方我有一个4核的CPU，那么这样一来，在单位时间内每个核只能跑一个线程，
然后时间片轮转切换。但是Python不一样，***它不管你有几个核，单位时间多个核只能跑一个线程***，
然后时间片轮转。看起来很不可思议？但是这就是GIL搞的鬼。任何Python线程执行前，
必须先获得GIL锁，然后，每执行100条字节码，解释器就自动释放GIL锁，
让别的线程有机会执行。这个GIL全局锁实际上把所有线程的执行代码都给上了锁，
所以，多线程在Python中只能交替执行，即使100个线程跑在100核CPU上，
也只能用到1个核。通常我们用的解释器是官方实现的CPython，要真正利用多核，
除非重写一个不带GIL的解释器。
- **重要概念** 
    1. Python多线程不适合计算密集型任务，但是可以利用在I/O密集型任务中；
        - `计算密集型任务`的特点是要进行大量的计算，消耗CPU资源，
        比如计算圆周率、对视频进行高清解码等等，全靠CPU的运算能力。
        这种计算密集型任务虽然也可以用多任务完成，但是任务越多，
        花在任务切换的时间就越多，CPU执行任务的效率就越低，所以，
        要最高效地利用CPU，**计算密集型任务同时进行的数量应当等于CPU的核心数**。
        计算密集型任务的特点是要进行大量的计算，消耗CPU资源，比如计算圆周率、
        对视频进行高清解码等等，全靠CPU的运算能力。
        这种计算密集型任务虽然也可以用多任务完成，但是任务越多，
        花在任务切换的时间就越多，CPU执行任务的效率就越低，所以，
        要最高效地利用CPU，计算密集型任务同时进行的数量应当等于CPU的核心数。
        - 第二种任务的类型是`IO密集型`，涉及到网络、磁盘IO的任务都是IO密集型任务，
        这类任务的特点是CPU消耗很少，任务的大部分时间都在等待IO操作完成
        _（因为IO的速度远远低于CPU和内存的速度）_。对于IO密集型任务，
        任务越多，CPU效率越高，但也有一个限度。
        常见的大部分任务都是IO密集型任务，比如Web应用。IO密集型任务执行期间，
        99%的时间都花在IO上，花在CPU上的时间很少，因此，
        用运行速度极快的C语言替换用Python这样运行速度极低的脚本语言，
        完全无法提升运行效率。对于IO密集型任务，
        最合适的语言就是开发效率最高（代码量最少）的语言，**脚本语言是首选，C语言最差**。

    2. Python虽然不能利用多线程实现多核任务，但可以通过**多进程**实现多核任务。
    多个Python进程有各自独立的GIL锁，互不影响。
    3. IO密集型代码(文件处理、网络爬虫等)，多线程能够有效提升效率(单线程下有IO操作会进行IO等待，
    造成不必要的时间浪费，而开启多线程能在线程A等待时，
    自动切换到线程B，可以不浪费CPU的资源，从而能提升程序执行效率)。
    所以python的多线程对IO密集型代码比较友好。
    4. 多核多线程比单核多线程更差，原因是单核下多线程，每次释放GIL，
    唤醒的那个线程都能获取到GIL锁，所以能够无缝执行，但多核下，
    CPU0释放GIL后，其他CPU上的线程都会进行竞争，
    但GIL可能会马上又被CPU0拿到，
    导致其他几个CPU上被唤醒后的线程会醒着等待到切换时间后又进入待调度状态，
    这样会造成线程颠簸(thrashing)，导致效率更低！ 
    
    5. 并发与并行
        - 多核CPU在某一时间段内同时执行多个进程(并行)
        - 在同一时间点内，同时执行多个进程(并发)
	6. 同步与异步
		- 同步(Sync)， 所谓同步，就是发出一个功能调用时，在没有得到结果之前，该调用就不返回或继续执行后续操作。
		- 异步(Async), 异步与同步相对，当一个异步过程调用发出后，调用者在没有得到结果之前，就可以继续执行后续操作。当这个调用完成后，一般通过状态、通知和回调来通知调用者。对于异步调用，调用的返回并不受调用者控制。
		- **异步**处理就是,你现在问我问题,我可以不回答你,等我用时间了再处理你这个问题.同步不就反之了，**同步**信息被立即处理 -- 直到信息处理完成才返回消息句柄；
		- 异步信息收到后将在后台处理一段时间 -- 而同步早在信息处理结束前就返回消息句柄
		- 举个例子简单说明下两者的区别：
> 同步：火车站多个窗口卖火车票，假设A窗口当卖第288张时，在这个短暂的过程中，其他窗口都不能卖这张票，也不能继续往下卖，必须这张票处理完其他窗口才能继续卖票。直白点说就是当你看见程序里出现**synchronized**这个关键字，将任务锁起来，当某个线程进来时，不能让其他线程继续进来，那就代表是同步了。

> 异步：当我们用手机下载某个视频时，我们大多数人都不会一直等着这个视频下载完，而是在下载的过程看看手机里的其他东西，比如用qq或者是微信聊聊天，这种的就是异步，你执行你的，我执行我的，互不干扰。比如上面卖火车票，如果多个窗口之间互不影响，我行我素，A窗口卖到第288张了，B窗口不管A窗口，自己也卖第288张票，那显然会出错了。

	7. 多线程多进程哪个更快？ 
		- 对CPU密集型代码(比如循环计算) - 多进程效率更高
		- 对IO密集型代码(比如文件操作，网络爬虫) - 多线程效率更高。
> 	为什么是这样呢？其实也不难理解。对于IO密集型操作，大部分消耗时间其实是等待时间，在等待时间中CPU是不需要工作的，那你在此期间提供双CPU资源也是利用不上的，相反对于CPU密集型代码，2个CPU干活肯定比一个CPU快很多。那么为什么多线程会对IO密集型代码有用呢？这时因为python碰到等待会释放GIL供新的线程使用，实现了线程间的切换。

---

### 2. 代码运行
#### 2.1 `multi_processing.py`
第一个代码multi_processing, 见用多进程机制处理一个耗时的计算问题: 

```
---------单进程------------------
当前母进程:16697
当前进程pid:16697
结果:1152921504606846976
当前进程pid:16697
结果:1152921504606846976
用时4.001805782318115s
---------多进程，两个进程进行两次循环----------
当前母进程:16697
等待所有子进程完成
子进程:16699---任务1
子进程:16700---任务2
结果:1152921504606846976
结果:1152921504606846976
总共用时2.021434783935547秒
```
可以发现，可见并发执行的时间明显比顺序执行要快很多。你还可以看到尽管我们只创建了两个进程，可实际运行中却包含里1个母进程和2个子进程。

**注意**
- 在使用2个子进程时，需要使用join()方法，这样使得母进程阻塞，否则输出时间只是母进程执行时间；
- 新创建的进程与进程的切换需要耗费资源，进程不可以开太多；
- 同时可以运行的进程数受限于cpu核数；可以 `import cpu_count` 来查看自己电脑的核数

#### 2.2 `multi_processing_pool.py`
- 第二个代码是利用multiprocess的Pool类来创建多进程:
	- Process 适合少量多进程的Task; 
	- 若进程数量很多，可以用循环，但需要手动管理系统中并发进行数量，这时候可以用`Pool`类，通过传递参数限制并发进程的数量，默认为cpu的核数； 
	- `Pool`类可以提供指定数量的进程； 当有新的请求提交到Pool中时，如果进程池还没有满，就会创建一个新的进程来执行请求，若池满，请求就会告知先等待，直到池中有进程结束，才会创建新的进程来执行这些请求； 
	- `Pool`类的几个常用方法： 
		- `aapply_async(func[, args=()[, kwds={}[, callback=None]]])`, 其作用是向进程池提交需要执行的函数及参数， 各个进程采用***非阻塞（异步）的调用方式***，即每个子进程只管运行自己的，**不管其它进程是否已经完成**。
		- `map(func, iterable[, chunksize=None])`, Pool类中的map方法，与内置的map函数用法行为基本一致，它**会使进程阻塞直到结果返回**。(虽然第二个参数是一个迭代器，但在实际使用中，必须在整个队列都就绪后，程序才会运行子进程) 
		- `map_async(func, iterable[, chunksize[, callback]])`, 与map用法一致，但是它是非阻塞的。其有关事项见apply_async。 
		- `close()`, 关闭进程池（pool），使其不在接受新的任务.
		- `terminate()`, 结束工作进程，不在处理未处理的任务.
		- `join()`,主进程阻塞等待子进程的退出， join方法要在close或terminate之后使用. 

```
当前cpu核数: 8
当前母进程:22059
等待所有子进程完成...
子进程:22060 --- 任务0
子进程:22061 --- 任务1
子进程:22062 --- 任务2
子进程:22063 --- 任务3
子进程:22064 --- 任务4
子进程:22065 --- 任务5
子进程:22066 --- 任务6
子进程:22067 --- 任务7
结果:1152921504606846976
结果:1152921504606846976
结果:1152921504606846976
结果:1152921504606846976
结果:1152921504606846976
子进程:22060 --- 任务8
结果:1152921504606846976结果:1152921504606846976结果:1152921504606846976
子进程:22061 --- 任务9
结果:1152921504606846976
结果:1152921504606846976
总共用时4.170361042022705秒
```

- 可以发现9个任务并行一共只需要4.17s 

#### 2.3 多进程间的数据共享与通信
一般来说，进程之间相互独立，每个进程都有独立的内存，通过共享内存**nmap模块**，进程之间可以共享对象，使多个进程可以访问同一个变量(地址相同,变量名可能不同)，多进程共享资源必然会导致进程相互竞争，所以尽可能防止使用共享状态。 

另一种方式是使用queue来实现不同进程间的通信或者数据共享(与多线程编程类似)... 

`multi_processing_queue.py`中创建了2个独立进程，一个负责写(pw), 一个负责读(pr)，实现了共享一个队列的queue ; 

```
Process to write:22396
Put A to queue...
Process to read:22397
Get A from queue...
Put B to queue...
Get B from queue...
Put C to queue...
Get C from queue...
```

#### 2.4 Python多线程与threading模块
python 3中的多进程编程主要依靠**threading模块**。创建新线程与创建新进程的方法非常类似。threading.Thread方法可以接收两个参数, 第一个是target，一般指向函数名，第二个时args，需要向函数传递的参数。对于创建的新线程，调用start()方法即可让其开始。我们还可以使用**current_thread().name**打印出当前线程的名字。 下例中我们使用多线程技术重构之前的计算代码。

- 必须+ `join()`，主线程和子线程其实是独立运行的； 
```
for t in thread_list: t.start()
for t in thread_list: t.join()
```
- `multi_threading.py`输出结果：
```
这是主线程：MainThread
当前子线程: Thread-1 任务1
当前子线程: Thread-2 任务2
结果: 1152921504606846976
结果: 1152921504606846976
总共用时2.004995107650757秒
```
- 当我们设置多线程时，主线程会创建多个子线程，在python中，默认情况下主线程和子线程**独立运行互不干涉**。如果希望让主线程等待子线程实现线程的同步，我们需要使用`join()`方法。如果我们希望一个主线程结束时不再执行子线程，我们应该怎么办呢? 我们可以使用`t.setDaemon(True)`； 代码如`multi_threading_setDaemon.py`
```
这是主线程：MainThread
当子线程: Thread-1
当子线程: Thread-2
当子线程: Thread-3
当子线程: Thread-4
当子线程: Thread-5
总共用时0.0016410350799560547秒
```
- 可以发现，主线程执行完后，直接结束了;  

#### 2.5 继承Thread类重写run方法创建新进程
除了使用Thread()方法创建新的线程外，我们还可以通过***继承Thread类重写run方法创建新的线程***，这种方法更灵活。下例中我们自定义的类为MyThread, 随后我们通过该类的**实例化创建了2个子线程**。
基本范式:

```
class MyThread(threading.Thread):
    def __init__(self,func,args,name='',):
        threading.Thread.__init__(self)
        self.func = func 
        self.args = args 
        self.name = name 

    def run(self):
        print('开始子进程{}'.format(self.name))
        self.result = self.func(self.args[0],)
        print("结果:{}".format(self.result))
        print('结束子进程{}'.format(self.name))
```

```
    start = time.time()
    threads = []
    for i in range(1,3):
        t = MyThread(long_time_task,(i,),str(i))
        threads.append(t)

    for  t in threads:
        t.start()
    for t in threads:
        t.join()
```

#### 2.6 不同线程间的数据共享
一个进程所含的不同线程间共享内存，这就意味着**任何一个变量都可以被任何一个线程修改**，因此线程之间共享数据**最大的危险在于多个线程同时改一个变量**，**把内容给改乱了**。如果不同线程间有共享的变量，其中一个方法就是在修改前给其上一把锁lock，确保一次只有一个线程能修改它。`threading.lock()`方法可以轻易实现对一个共享变量的锁定，修改完后`release`供其它线程使用。

- `multi_processing_lock.py`中，账户余额balance是一个共享变量，使用lock可以使其不被改乱。 ***用线程修改一个共享变量的基本范式***
```
# 获得锁 
lock.acquire() 
for i in range(0,100000):
    self.balance += 1 
# 释放锁 
lock.release() 
```


#### 2.7 使用queue队列通信-经典的生产者消费者模型
另一种实现不同线程间数据共享的方法就是使用消息队列queue。不像列表，queue是线程安全的，可以放心使用; 

`multi_threading_queue.py`中创建了两个线程，一个负责生成，一个负责消费，所生成的**产品存放在queue**里，实现了**不同线程间沟通**。

```
# 生产者Producer
class Producer(threading.Thread):
    def __init__(self,name,queue):
        threading.Thread.__init__(self,name=name)
        self.queue = queue

    def run(self):
        for i in range(1,5):
            print("{}生产{}到Queue了！".format(self.getName(),i))
            self.queue.put(i)
            time.sleep(random.randrange(10)/5)
        print("%s 结束!" % self.getName())

# 消费者Consumer
class Consumer(threading.Thread):
    def __init__(self,name,queue):
        threading.Thread.__init__(self,name=name)
        self.queue = queue

    def run(self):
        for i in range(1,5):
            val = self.queue.get()
            print("{}正在消费Queue中的{}".format(self.getName(),val))
            time.sleep(random.randrange(10))
        print("%s 结束!" % self.getName())
```

- 队列queue的put方法可以将一个对象obj放入队列中。如果队列已满，此方法将阻塞至队列有空间可用为止。
- queue的get方法一次返回队列中的一个成员。如果队列为空，此方法将阻塞至队列中有成员可用为止。
- queue同时还自带emtpy(), full()等方法来判断一个队列是否为空或已满，但是这些方法并不可靠，因为多线程和多进程，在返回结果和使用结果之间，队列中可能添加/删除了成员。




	
